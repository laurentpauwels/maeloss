%% This BibTeX bibliography file was created using BibDesk.
%% https://bibdesk.sourceforge.io/

%% Created for Laurent at 2020-08-09 14:49:33 +1000 


%% Saved with string encoding Unicode (UTF-8) 



@inbook{Chan:2020,
	Abstract = {This chapter summarises the recent approaches to optimal forecast combination from a frequentist perspective. The availability of big data leads to the development of many different models of the same macroeconomic variables. The challenge is to seek the best way to combine all relevant information from big data to create optimal forecast. Forecast combination provides one plausible approach. This chapter discusses the practical aspects of combining forecasts optimally and theoretical properties of the combination both for point forecasts and density forecasts. Specifically, the chapter derives the asymptotic distributions of the estimated optimal weight under two of the most popular forecasting criteria: Mean Squared Forecast Error and Mean Absolute Deviation. This chapter also revisits the insights of the so-called forecast combination puzzle, which shows that in practice a simple average of forecasts outperforms more complex weighting strategies. These theoretical results help address the puzzle by providing a mean to test statistically the difference between the estimated optimal weight and the simple average. The optimal weights obtained from minimising the Kullback--Leibler Information Criterion (KLIC) are discussed in the context of density forecast combination. This chapter also proposes a novel Generalized Method of Moments approach for density forecast combination. The connection between the proposed approach and the conventional approach by minimising KLIC is also investigated in some details.},
	Address = {Cham},
	Author = {Chan, Felix and Pauwels, Laurent and Soltyk, Sylvia},
	Booktitle = {Macroeconomic Forecasting in the Era of Big Data: Theory and Practice},
	Date-Added = {2020-08-09 14:49:11 +1000},
	Date-Modified = {2020-08-09 14:49:16 +1000},
	Doi = {10.1007/978-3-030-31150-6_11},
	Editor = {Fuleky, Peter},
	Isbn = {978-3-030-31150-6},
	Pages = {329--357},
	Publisher = {Springer International Publishing},
	Title = {Frequentist Averaging},
	Url = {https://doi.org/10.1007/978-3-030-31150-6_11},
	Year = {2020},
	Bdsk-Url-1 = {https://doi.org/10.1007/978-3-030-31150-6_11}}

@book{Clarke:1990,
	Author = {Clarke, Frank H.},
	Date-Added = {2020-08-09 14:29:51 +1000},
	Date-Modified = {2020-08-09 14:30:05 +1000},
	Doi = {10.1137/1.9781611971309},
	Eprint = {https://epubs.siam.org/doi/pdf/10.1137/1.9781611971309},
	Publisher = {Society for Industrial and Applied Mathematics},
	Title = {Optimization and Nonsmooth Analysis},
	Url = {https://epubs.siam.org/doi/abs/10.1137/1.9781611971309},
	Year = {1990},
	Bdsk-Url-1 = {https://epubs.siam.org/doi/abs/10.1137/1.9781611971309},
	Bdsk-Url-2 = {https://doi.org/10.1137/1.9781611971309}}

@inbook{doi:10.1137/1.9781611971309.ch2,
	Booktitle = {Optimization and Nonsmooth Analysis},
	Date-Added = {2020-08-09 14:28:27 +1000},
	Date-Modified = {2020-08-09 14:28:27 +1000},
	Doi = {10.1137/1.9781611971309.ch2},
	Eprint = {https://epubs.siam.org/doi/pdf/10.1137/1.9781611971309.ch2},
	Pages = {24-109},
	Title = {2. Generalized Gradients},
	Url = {https://epubs.siam.org/doi/abs/10.1137/1.9781611971309.ch2},
	Bdsk-Url-1 = {https://epubs.siam.org/doi/abs/10.1137/1.9781611971309.ch2},
	Bdsk-Url-2 = {https://doi.org/10.1137/1.9781611971309.ch2}}

@article{Patton:2019,
	Author = {Andrew J. Patton},
	Date-Added = {2020-06-29 14:33:47 +1000},
	Date-Modified = {2020-06-29 14:33:53 +1000},
	Doi = {10.1080/07350015.2019.1585256},
	Eprint = {https://doi.org/10.1080/07350015.2019.1585256},
	Journal = {Journal of Business \& Economic Statistics},
	Number = {0},
	Pages = {1-23},
	Publisher = {Taylor & Francis},
	Title = {Comparing Possibly Misspecified Forecasts},
	Url = {https://doi.org/10.1080/07350015.2019.1585256},
	Volume = {0},
	Year = {2019},
	Bdsk-Url-1 = {https://doi.org/10.1080/07350015.2019.1585256}}

@article{Rendon:2019,
	Abstract = {This article draws from research on ensembles in computational intelligence to propose structural combinations of forecasts, which are point forecast combinations that are based on information from the parameters of the individual models that generated the forecasts. Two types of structural combination are proposed which use seasonal exponential smoothing as base models, and are applied to forecast short-term electricity demand. Although forecasting performance may depend on how ensembles are generated, results show that the proposed combinations can outperform competitive benchmarks. The methods can be used to forecast other seasonal data and be extended to different types of forecasting models.},
	Author = {Juan F. Rendon-Sanchez and Lilian M. {de Menezes}},
	Date-Added = {2020-06-29 12:19:31 +1000},
	Date-Modified = {2020-06-29 12:32:43 +1000},
	Doi = {https://doi.org/10.1016/j.ejor.2018.12.013},
	Issn = {0377-2217},
	Journal = {European Journal of Operational Research},
	Keywords = {Forecasting, Combination of forecasts, Electricity demand/load forecasting, Ensembles, Exponential smoothing methods},
	Number = {3},
	Pages = {916 - 924},
	Title = {Structural combination of seasonal exponential smoothing forecasts applied to load forecasting},
	Url = {http://www.sciencedirect.com/science/article/pii/S0377221718310518},
	Volume = {275},
	Year = {2019},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0377221718310518},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.ejor.2018.12.013}}

@article{Cang:2014,
	Author = {Cang, S. and Yu, H.},
	Date-Added = {2020-06-29 12:10:44 +1000},
	Date-Modified = {2020-06-29 12:10:56 +1000},
	Document_Type = {Article},
	Doi = {10.1016/j.ejor.2013.08.045},
	Journal = {European Journal of Operational Research},
	Note = {cited By 32},
	Number = {1},
	Pages = {127-139},
	Source = {Scopus},
	Title = {A combination selection algorithm on forecasting},
	Url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84890424903&doi=10.1016%2fj.ejor.2013.08.045&partnerID=40&md5=eab17f7462c2fa9e0ba8a90cab113f92},
	Volume = {234},
	Year = {2014},
	Bdsk-Url-1 = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84890424903&doi=10.1016%2fj.ejor.2013.08.045&partnerID=40&md5=eab17f7462c2fa9e0ba8a90cab113f92},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.ejor.2013.08.045}}

@article{deMenezes:2000,
	Abstract = {A large literature has evolved in the thirty years since the seminal work on combining forecasts. Despite this, when evaluating performance we only look at measures of accuracy and thus ignore most of the rigour of time series analysis. Furthermore, the output from a combination of forecasts is just a single point estimate which is insufficient for business planning models that take explicit account of risk and uncertainty. In this paper, we review evidence on the performance of different combining methods with the aim of providing practical guidelines based on three properties of the forecast errors: variance, asymmetry and serial correlation. The evidence indicates that using different criteria leads to distinct preferences, and that the properties of the individual forecast errors can strongly influence the characteristics of the combination's errors. We show that a practical approach to combining also requires a degree of judgement on the attributes of error specification.},
	Author = {Lilian M. {de Menezes} and Derek W. {Bunn} and James W Taylor},
	Date-Added = {2020-06-29 12:05:08 +1000},
	Date-Modified = {2020-06-29 12:06:57 +1000},
	Doi = {https://doi.org/10.1016/S0377-2217(98)00380-4},
	Issn = {0377-2217},
	Journal = {European Journal of Operational Research},
	Keywords = {Forecasting, Combinations, Error specification, Guidelines},
	Number = {1},
	Pages = {190 - 204},
	Title = {Review of guidelines for the use of combined forecasts},
	Url = {http://www.sciencedirect.com/science/article/pii/S0377221798003804},
	Volume = {120},
	Year = {2000},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0377221798003804},
	Bdsk-Url-2 = {https://doi.org/10.1016/S0377-2217(98)00380-4}}

@article{Genre:2013,
	Abstract = {This paper explores the gains from combining expert forecasts from the ECB Survey of Professional Forecasters (SPF). The analysis encompasses combinations based on principal components and trimmed means, performance-based weighting, and least squares estimates of optimal weights, as well as Bayesian shrinkage. For GDP growth and the unemployment rate, only few of the individual forecast combination schemes outperform the simple equally weighted average forecast in a pseudo-out-of-sample analysis, while there is stronger evidence of improvement over this benchmark for the inflation rate. Nonetheless, when we account for the effect of multiple model comparisons through White's reality check, the results caution against any assumption that the improvements identified would persist in the future.},
	Author = {V{{\'e}}ronique Genre and Geoff Kenny and Aidan Meyler and Allan Timmermann},
	Date-Added = {2020-06-29 11:53:28 +1000},
	Date-Modified = {2020-06-29 11:56:17 +1000},
	Doi = {https://doi.org/10.1016/j.ijforecast.2012.06.004},
	Issn = {0169-2070},
	Journal = {International Journal of Forecasting},
	Keywords = {Forecast combination, Forecast evaluation, Multiple model comparisons, Real-time data, Survey of Professional Forecasters},
	Number = {1},
	Pages = {108 - 121},
	Title = {Combining expert forecasts: Can anything beat the simple average?},
	Url = {http://www.sciencedirect.com/science/article/pii/S016920701200088X},
	Volume = {29},
	Year = {2013},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S016920701200088X},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.ijforecast.2012.06.004}}

@article{Bowles:2010,
	Author = {Carlos Bowles and Roberta Friz and Veronique Genre and Geoff Kenny and Aidan Meyler and Tuomas Rautanen},
	Date-Added = {2020-06-29 11:39:52 +1000},
	Date-Modified = {2020-06-30 16:54:33 +1000},
	Doi = {https://doi.org/https://doi.org/10.1787/jbcma-2010-5km33sg210kk},
	Title = {An Evaluation of the Growth and Unemployment Forecasts in the {ECB Survey of Professional Forecasters}},
	Url = {https://www.oecd-ilibrary.org/content/paper/jbcma-2010-5km33sg210kk},
	Year = {2010},
	Bdsk-Url-1 = {https://www.oecd-ilibrary.org/content/paper/jbcma-2010-5km33sg210kk},
	Bdsk-Url-2 = {https://doi.org/https://doi.org/10.1787/jbcma-2010-5km33sg210kk}}

@techreport{Garcia:2003,
	Abstract = {This paper provides a detailed overview of the ECB JEL Classification: C8, E31},
	Author = {Garc{{\'\i}}a, Juan Angel},
	Date-Added = {2020-06-29 11:36:49 +1000},
	Date-Modified = {2020-06-29 11:58:33 +1000},
	Institution = {European Central Bank},
	Keywords = {inflation; macroeconomic forecasts; surveys},
	Month = Sep,
	Number = {8},
	Title = {{An introduction to the ECB's survey of professional forecasters}},
	Type = {Occasional Paper Series},
	Url = {https://ideas.repec.org/p/ecb/ecbops/20038.html},
	Year = 2003,
	Bdsk-Url-1 = {https://ideas.repec.org/p/ecb/ecbops/20038.html}}

@techreport{ECB:2007,
	Abstract = {Eight years have passed since the European Central Bank (ECB) launched its Survey of Professional Forecasters (SPF). The SPF asks a panel of approximately 75 forecasters located in the European Union (EU) for their short- to longer-term expectations for macroeconomic variables such as euro area inflation, growth and unemployment. This paper provides an initial assessment of the information content of this survey. First, we consider shorter-term (i.e., one- and two-year ahead rolling horizon) forecasts. The analysis suggests that, over the sample period, in common with other private and institutional forecasters, the SPF systematically under-forecast inflation but that there is less evidence of such systematic errors for GDP and unemployment forecasts. However, these findings, which generally hold regardless of whether one considers the aggregate SPF panel or individual responses, should be interpreted with caution given the relatively short sample period available for the analysis. Second, we consider SPF respondents JEL Classification: C83, E37, E50},
	Author = {Kenny, Geoff and Genre, V{\'e}ronique and Bowles, Carlos and Friz, Roberta and Meyler, Aidan and Rautanen, Tuomas},
	Date-Added = {2020-06-29 11:33:44 +1000},
	Date-Modified = {2020-06-29 11:33:56 +1000},
	Institution = {European Central Bank},
	Keywords = {evaluation; expectations; macroeconomic forecasts; uncertainty},
	Month = Apr,
	Number = {59},
	Title = {{The ECB survey of professional forecasters (SPF) - A review after eight years' experience}},
	Type = {Occasional Paper Series},
	Url = {https://ideas.repec.org/p/ecb/ecbops/200759.html},
	Year = 2007,
	Bdsk-Url-1 = {https://ideas.repec.org/p/ecb/ecbops/200759.html}}

@article{Hyndman:2017,
	Abstract = {This paper introduces the concept of Temporal Hierarchies for time series forecasting. A temporal hierarchy can be constructed for any time series by means of non-overlapping temporal aggregation. Predictions constructed at all aggregation levels are combined with the proposed framework to result in temporally reconciled, accurate and robust forecasts. The implied combination mitigates modelling uncertainty, while the reconciled nature of the forecasts results in a unified prediction that supports aligned decisions at different planning horizons: from short-term operational up to long-term strategic planning. The proposed methodology is independent of forecasting models. It can embed high level managerial forecasts that incorporate complex and unstructured information with lower level statistical forecasts. Our results show that forecasting with temporal hierarchies increases accuracy over conventional forecasting, particularly under increased modelling uncertainty. We discuss organisational implications of the temporally reconciled forecasts using a case study of Accident & Emergency departments.},
	Author = {George Athanasopoulos and Rob J. Hyndman and Nikolaos Kourentzes and Fotios Petropoulos},
	Date-Added = {2020-06-29 11:19:58 +1000},
	Date-Modified = {2020-06-29 11:20:12 +1000},
	Doi = {https://doi.org/10.1016/j.ejor.2017.02.046},
	Issn = {0377-2217},
	Journal = {European Journal of Operational Research},
	Keywords = {Forecasting, Hierarchical forecasting, Temporal aggregation, Reconciliation, Forecast combination},
	Number = {1},
	Pages = {60 - 74},
	Title = {Forecasting with temporal hierarchies},
	Url = {http://www.sciencedirect.com/science/article/pii/S0377221717301911},
	Volume = {262},
	Year = {2017},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0377221717301911},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.ejor.2017.02.046}}

@article{Panagiotelis:2019,
	Abstract = {New methods are proposed for adjusting probabilistic forecasts to ensure coherence with the aggregation constraints inherent in temporal hierarchies. The different approaches nested within this framework include methods that exploit information at all levels of the hierarchy as well as a novel method based on cross-validation. The methods are evaluated using real data from two wind farms in Crete and electric load in Boston. For these applications, optimal decisions related to grid operations and bidding strategies are based on coherent probabilistic forecasts of energy power. Empirical evidence is also presented showing that probabilistic forecast reconciliation improves the accuracy of the probabilistic forecasts.},
	Author = {Jooyoung Jeon and Anastasios Panagiotelis and Fotios Petropoulos},
	Date-Added = {2020-06-29 11:17:56 +1000},
	Date-Modified = {2020-06-29 11:18:19 +1000},
	Doi = {https://doi.org/10.1016/j.ejor.2019.05.020},
	Issn = {0377-2217},
	Journal = {European Journal of Operational Research},
	Keywords = {Forecasting, Temporal hierarchies, Cross-validation, Aggregation, Renewable energy generation},
	Number = {2},
	Pages = {364 - 379},
	Title = {Probabilistic forecast reconciliation with applications to wind power and electric load},
	Url = {http://www.sciencedirect.com/science/article/pii/S0377221719304242},
	Volume = {279},
	Year = {2019},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0377221719304242},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.ejor.2019.05.020}}

@article{Diebold:2019,
	Abstract = {Despite the clear success of forecast combination in many economic environments, several important issues remain incompletely resolved. The issues relate to the selection of the set of forecasts to combine, and whether some form of additional regularization (e.g., shrinkage) is desirable. Against this background, and also considering the frequently-found good performance of simple-average combinations, we propose a LASSO-based procedure that sets some combining weights to zero and shrinks the survivors toward equality (``partially-egalitarian LASSO''). Ex post analysis reveals that the optimal solution has a very simple form: the vast majority of forecasters should be discarded, and the remainder should be averaged. We therefore propose and explore direct subset-averaging procedures that are motivated by the structure of partially-egalitarian LASSO and the lessons learned, which, unlike LASSO, do not require the choice of a tuning parameter. Intriguingly, in an application to the European Central Bank Survey of Professional Forecasters, our procedures outperform simple average and median forecasts; indeed, they perform approximately as well as the ex post best forecaster.},
	Author = {Francis X. Diebold and Minchul Shin},
	Date-Added = {2020-06-29 11:01:44 +1000},
	Date-Modified = {2020-06-29 11:01:52 +1000},
	Doi = {https://doi.org/10.1016/j.ijforecast.2018.09.006},
	Issn = {0169-2070},
	Journal = {International Journal of Forecasting},
	Keywords = {Forecast combination, Forecast surveys, Shrinkage, Model selection, LASSO, Regularization},
	Number = {4},
	Pages = {1679 - 1691},
	Title = {Machine learning for regularized survey forecast combination: Partially-egalitarian LASSO and its derivatives},
	Url = {http://www.sciencedirect.com/science/article/pii/S0169207018301596},
	Volume = {35},
	Year = {2019},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0169207018301596},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.ijforecast.2018.09.006}}

@article{Conflitti:2015,
	Abstract = {We consider the problem of combining individual forecasts of real gross domestic product (GDP) growth and Harmonized Index of Consumer Prices (HICP) inflation from the Survey of Professional Forecasters (SPF) for the Euro area. Contrary to the common practice of using equal combination weights, we compute weights which are optimal in the sense that they minimize the mean square forecast error (MSFE) in the case of point forecasts and maximize a logarithmic score in the case of density forecasts. We show that this is a viable strategy even when the number of forecasts to be combined gets large, provided that we constrain these weights to be positive and to sum to one. Indeed, this enforces a form of shrinkage on the weights which ensures a reasonable out-of-sample performance of the combined forecasts.},
	Author = {Cristina Conflitti and Christine {De Mol} and Domenico Giannone},
	Date-Added = {2020-06-29 10:58:19 +1000},
	Date-Modified = {2020-06-30 16:53:02 +1000},
	Doi = {https://doi.org/10.1016/j.ijforecast.2015.03.009},
	Issn = {0169-2070},
	Journal = {International Journal of Forecasting},
	Keywords = {Forecast combination, Forecast evaluation, Survey of Professional Forecasters, Real-time data, Shrinkage, High-dimensional data},
	Number = {4},
	Pages = {1096 - 1103},
	Title = {Optimal combination of survey forecasts},
	Url = {http://www.sciencedirect.com/science/article/pii/S0169207015000606},
	Volume = {31},
	Year = {2015},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0169207015000606},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.ijforecast.2015.03.009}}

@article{Bjornland:2012,
	Abstract = {Abstract We develop a system that provides model-based forecasts for inflation in Norway. We recursively evaluate quasi out-of-sample forecasts from a large suite of models from 1999 to 2009. The performance of the models are then used to derive quasi real time weights that are used to combine the forecasts. Our results indicate that a combination forecast improves upon the point forecasts from individual models. Furthermore, a combination forecast outperforms Norges Bank's own point forecast for inflation. The beneficial results are obtained using a trimmed weighted average. Some degree of trimming is required for the combination forecasts to outperform the judgmental forecasts from the policymaker.},
	Author = {Bj{\o}rnland, Hilde C. and Gerdrup, Karsten and Jore, Anne Sofie and Smith, Christie and Thorsrud, Leif Anders},
	Date-Added = {2020-06-29 10:55:42 +1000},
	Date-Modified = {2020-06-29 10:55:55 +1000},
	Doi = {10.1111/j.1468-0084.2011.00639.x},
	Eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1468-0084.2011.00639.x},
	Journal = {Oxford Bulletin of Economics and Statistics},
	Keywords = {E52, E37, E47},
	Number = {2},
	Pages = {163-179},
	Title = {Does Forecast Combination Improve Norges Bank Inflation Forecasts?*},
	Url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1468-0084.2011.00639.x},
	Volume = {74},
	Year = {2012},
	Bdsk-Url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1468-0084.2011.00639.x},
	Bdsk-Url-2 = {https://doi.org/10.1111/j.1468-0084.2011.00639.x}}

@article{Lichtendahl:2013,
	Abstract = {We consider two ways to aggregate expert opinions using simple averages: averaging probabilities and averaging quantiles. We examine analytical properties of these forecasts and compare their ability to harness the wisdom of the crowd. In terms of location, the two average forecasts have the same mean. The average quantile forecast is always sharper: it has lower variance than the average probability forecast. Even when the average probability forecast is overconfident, the shape of the average quantile forecast still offers the possibility of a better forecast. Using probability forecasts for gross domestic product growth and inflation from the Survey of Professional Forecasters, we present evidence that both when the average probability forecast is overconfident and when it is underconfident, it is outperformed by the average quantile forecast. Our results show that averaging quantiles is a viable alternative and indicate some conditions under which it is likely to be more useful than averaging probabilities. This paper was accepted by Peter Wakker, decision analysis.},
	Author = {Kenneth C. Lichtendahl and Yael Grushka-Cockayne and Robert L. Winkler},
	Date-Added = {2020-06-19 17:23:34 +1000},
	Date-Modified = {2020-06-19 17:23:47 +1000},
	Doi = {10.1287/mnsc.1120.1667},
	Journal = {Management Science},
	Keywords = {probability forecasts; quantile forecasts; expert combination; linear opinion pooling},
	Month = {July},
	Number = {7},
	Pages = {1594-1611},
	Title = {{Is It Better to Average Probabilities or Quantiles?}},
	Url = {https://ideas.repec.org/a/inm/ormnsc/v59y2013i7p1594-1611.html},
	Volume = {59},
	Year = 2013,
	Bdsk-Url-1 = {https://ideas.repec.org/a/inm/ormnsc/v59y2013i7p1594-1611.html},
	Bdsk-Url-2 = {https://doi.org/10.1287/mnsc.1120.1667}}

@article{Larrick:2006,
	Abstract = { Averaging estimates is an effective way to improve accuracy when combining expert judgments, integrating group members' judgments, or using advice to modify personal judgments. If the estimates of two judges ever fall on different sides of the truth, which we term bracketing, averaging must outperform the average judge for convex loss functions, such as mean absolute deviation (MAD). We hypothesized that people often hold incorrect beliefs about averaging, falsely concluding that the average of two judges' estimates would be no more accurate than the average judge. The experiments confirmed that this misconception was common across a range of tasks that involved reasoning from summary data (Experiment 1), from specific instances (Experiment 2), and conceptually (Experiment 3). However, this misconception decreased as observed or assumed bracketing rate increased (all three studies) and when bracketing was made more transparent (Experiment 2). Experiment 4 showed that flawed inferential rules and poor extensional reasoning abilities contributed to the misconception. We conclude by describing how people may face few opportunities to learn the benefits of averaging and how misappreciating averaging contributes to poor intuitive strategies for combining estimates. },
	Author = {Larrick, Richard P. and Soll, Jack B.},
	Date-Added = {2020-06-19 17:22:11 +1000},
	Date-Modified = {2020-06-19 17:22:21 +1000},
	Doi = {10.1287/mnsc.1050.0459},
	Eprint = {https://doi.org/10.1287/mnsc.1050.0459},
	Journal = {Management Science},
	Number = {1},
	Pages = {111-127},
	Title = {Intuitions About Combining Opinions: Misappreciation of the Averaging Principle},
	Url = {https://doi.org/10.1287/mnsc.1050.0459},
	Volume = {52},
	Year = {2006},
	Bdsk-Url-1 = {https://doi.org/10.1287/mnsc.1050.0459}}

@article{Soll:2009,
	Abstract = {A basic issue in social influence is how best to change one's judgment in response to learning the opinions of others. This article examines the strategies that people use to revise their quantitative estimates on the basis of the estimates of another person. The authors note that people tend to use 2 basic strategies when revising estimates: choosing between the 2 estimates and averaging them. The authors developed the probability, accuracy, redundancy (PAR) model to examine the relative effectiveness of these two strategies across judgment environments. A surprising result was that averaging was the more effective strategy across a wide range of commonly encountered environments. The authors observed that despite this finding, people tend to favor the choosing strategy. Most participants in these studies would have achieved greater accuracy had they always averaged. The identification of intuitive strategies, along with a formal analysis of when they are accurate, provides a basis for examining how effectively people use the judgments of others. Although a portfolio of strategies that includes averaging and choosing can be highly effective, the authors argue that people are not generally well adapted to the environment in terms of strategy selection.},
	Address = {Fuqua School of Business, Duke University, Durham, NC 27708, USA. jsoll{\char64}duke.edu},
	Author = {Soll, Jack B and Larrick, Richard P},
	Copyright = {Copyright 2009 APA, all rights reserved.},
	Crdt = {2009/04/22 09:00},
	Date = {2009 May},
	Date-Added = {2020-06-19 17:19:48 +1000},
	Date-Modified = {2020-06-30 16:55:32 +1000},
	Dcom = {20090626},
	Doi = {10.1037/a0015145},
	Edat = {2009/04/22 09:00},
	Issn = {0278-7393 (Print); 0278-7393 (Linking)},
	Jid = {8207540},
	Journal = {Journal of Experimental Psychology Learning Memory Cognition},
	Jt = {Journal of experimental psychology. Learning, memory, and cognition},
	Language = {eng},
	Lid = {10.1037/a0015145 {$[$}doi{$]$}},
	Lr = {20090421},
	Mh = {*Choice Behavior; Concept Formation; Cues; Culture; *Decision Making; *Feedback; Humans; *Intuition; *Judgment; Peer Group; Probability Learning; *Social Environment},
	Mhda = {2009/06/27 09:00},
	Month = {May},
	Number = {3},
	Own = {NLM},
	Pages = {780--805},
	Phst = {2009/04/22 09:00 {$[$}entrez{$]$}; 2009/04/22 09:00 {$[$}pubmed{$]$}; 2009/06/27 09:00 {$[$}medline{$]$}},
	Pii = {2009-05251-012},
	Pl = {United States},
	Pmid = {19379049},
	Pst = {ppublish},
	Pt = {Journal Article},
	Sb = {IM},
	Status = {MEDLINE},
	Title = {Strategies for revising judgment: how (and how well) people use others' opinions.},
	Volume = {35},
	Year = {2009},
	Bdsk-Url-1 = {https://doi.org/10.1037/a0015145}}

@article{Winkler:1992,
	Abstract = { In the combination of forecasts, weighted averages that attempt to take into account the accuracy of the forecasts and any dependence among forecasts tend to perform poorly in practice. An important factor influencing this performance is the sensitivity, or instability, of the estimated weights used to generate the combined forecast. The intent of this paper is to look at this instability via graphs and the sampling distribution of the weights. Results are developed for the combination of two forecasts and extended to the m-forecast case by viewing the m-forecast case as a sequence of two-forecast combinations. },
	Author = {Winkler, Robert L. and Clemen, Robert T.},
	Date-Added = {2018-11-28 13:32:34 +1100},
	Date-Modified = {2018-11-28 13:32:43 +1100},
	Doi = {10.1287/opre.40.3.609},
	Eprint = {https://doi.org/10.1287/opre.40.3.609},
	Journal = {Operations Research},
	Number = {3},
	Pages = {609-614},
	Title = {Sensitivity of Weights in Combining Forecasts},
	Url = {https://doi.org/10.1287/opre.40.3.609},
	Volume = {40},
	Year = {1992},
	Bdsk-Url-1 = {https://doi.org/10.1287/opre.40.3.609}}

@article{Grushka:2017,
	Abstract = { Firms today average forecasts collected from multiple experts and models. Because of cognitive biases, strategic incentives, or the structure of machine-learning algorithms, these forecasts are often overfit to sample data and are overconfident. Little is known about the challenges associated with aggregating such forecasts. We introduce a theoretical model to examine the combined effect of overfitting and overconfidence on the average forecast. Their combined effect is that the mean and median probability forecasts are poorly calibrated with hit rates of their prediction intervals too high and too low, respectively. Consequently, we prescribe the use of a trimmed average, or trimmed opinion pool, to achieve better calibration. We identify the random forest, a leading machine-learning algorithm that pools hundreds of overfit and overconfident regression trees, as an ideal environment for trimming probabilities. Using several known data sets, we demonstrate that trimmed ensembles can significantly improve the random forest's predictive accuracy. This paper was accepted by James Smith, decision analysis. },
	Author = {Grushka-Cockayne, Yael and Jose, Victor Richmond R. and Lichtendahl, Kenneth C.},
	Date-Added = {2018-11-28 13:31:20 +1100},
	Date-Modified = {2018-11-28 13:31:37 +1100},
	Doi = {10.1287/mnsc.2015.2389},
	Eprint = {https://doi.org/10.1287/mnsc.2015.2389},
	Journal = {Management Science},
	Number = {4},
	Pages = {1110-1130},
	Title = {Ensembles of Overfit and Overconfident Forecasts},
	Url = {https://doi.org/10.1287/mnsc.2015.2389},
	Volume = {63},
	Year = {2017},
	Bdsk-Url-1 = {https://doi.org/10.1287/mnsc.2015.2389}}

@article{Banerjee:2005,
	Author = {A. Banerjee and Xin Guo and Hui Wang},
	Date-Added = {2018-11-28 13:04:44 +1100},
	Date-Modified = {2018-11-28 13:04:53 +1100},
	Doi = {10.1109/TIT.2005.850145},
	Issn = {0018-9448},
	Journal = {IEEE Transactions on Information Theory},
	Keywords = {least mean squares methods;optimisation;prediction theory;random processes;random variable prediction;conditional expectation;optimal predictor;Bregman loss function;BLF;Random variables;Sufficient conditions;Information theory;Operations research;Industrial engineering;Mathematics;Bregman loss functions (BLFs);conditional expectation;prediction},
	Month = {July},
	Number = {7},
	Pages = {2664-2669},
	Title = {On the optimality of conditional expectation as a Bregman predictor},
	Volume = {51},
	Year = {2005},
	Bdsk-Url-1 = {https://doi.org/10.1109/TIT.2005.850145}}

@article{Savage:1971,
	Abstract = {Proper scoring rules, i.e., devices of a certain class for eliciting a person's probabilities and other expectations, are studied, mainly theoretically but with some speculations about application. The relation of proper scoring rules to other economic devices and to the foundations of the personalistic theory of probability is brought out. The implications of various restrictions, especially symmetry restrictions, on scoring rules is explored, usually with a minimum of regularity hypothesis.},
	Author = {Leonard J. Savage},
	Date-Added = {2018-11-28 13:02:18 +1100},
	Date-Modified = {2018-11-28 13:02:27 +1100},
	Issn = {01621459},
	Journal = {Journal of the American Statistical Association},
	Number = {336},
	Pages = {783--801},
	Publisher = {[American Statistical Association, Taylor & Francis, Ltd.]},
	Title = {Elicitation of Personal Probabilities and Expectations},
	Url = {http://www.jstor.org/stable/2284229},
	Volume = {66},
	Year = {1971},
	Bdsk-Url-1 = {http://www.jstor.org/stable/2284229}}

@article{Bregman:1967,
	Abstract = {IN this paper we consider an iterative method of finding the common point of convex sets. This method can be regarded as a generalization of the methods discussed in [1--4]. Apart from problems which can be reduced to finding some point of the intersection of convex sets, the method considered can be applied to the approximate solution of problems in linear and convex programming.},
	Author = {L.M. Bregman},
	Date-Added = {2018-11-28 13:01:16 +1100},
	Date-Modified = {2018-11-28 13:01:26 +1100},
	Doi = {https://doi.org/10.1016/0041-5553(67)90040-7},
	Issn = {0041-5553},
	Journal = {USSR Computational Mathematics and Mathematical Physics},
	Number = {3},
	Pages = {200 - 217},
	Title = {The relaxation method of finding the common point of convex sets and its application to the solution of problems in convex programming},
	Url = {http://www.sciencedirect.com/science/article/pii/0041555367900407},
	Volume = {7},
	Year = {1967},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/0041555367900407},
	Bdsk-Url-2 = {https://doi.org/10.1016/0041-5553(67)90040-7}}

@article{Peng:2015,
	Author = {J. Peng and S. Yue and H. Li},
	Date-Added = {2018-11-28 12:34:13 +1100},
	Date-Modified = {2018-11-28 13:23:41 +1100},
	Doi = {10.1109/TIT.2015.2429611},
	Issn = {0018-9448},
	Journal = {IEEE Transactions on Information Theory},
	Keywords = {linear systems;minimisation;NP-CMP equivalence;sparsity models l0minimization;information processing;underdetermined linear system;lp-norm minimization problem;Minimization;Linear programming;Information processing;Linear systems;Optimization;Sparse matrices;Computational modeling;Information processing;Sparse representation;Sparse recovery;lp minimization;Underdetermined linear system;Information processing;sparse representation;sparse recovery;$l_{p}$ minimization;underdetermined linear system},
	Month = {July},
	Number = {7},
	Pages = {4028-4033},
	Title = {{NP/CMP} Equivalence: A Phenomenon Hidden Among Sparsity Models $l_{0}$ Minimization and $l_{p}$ Minimization for Information Processing},
	Volume = {61},
	Year = {2015},
	Bdsk-Url-1 = {https://doi.org/10.1109/TIT.2015.2429611}}

@article{Fung:2011,
	Author = {Glenn Fung and O. L. Mangasarian},
	Date-Added = {2018-11-28 12:14:33 +1100},
	Date-Modified = {2018-11-28 12:41:32 +1100},
	Doi = {10.1007/s10957-011-9871-x},
	Journal = {Journal of Optimization Theory and Applications},
	Month = {10},
	Pages = {1-10},
	Title = {Equivalence of Minimal $0$- and $p$-Norm Solutions of Linear Equalities, Inequalities and Linear Programs for Sufficiently Small p},
	Volume = {151},
	Year = {2011},
	Bdsk-Url-1 = {https://doi.org/10.1007/s10957-011-9871-x}}

@article{Matsypura:2018,
	Abstract = {Combinations of point forecasts from expert forecasters are known to frequently outperform individual forecasts. It is also well documented that combination by simple averaging very often has performance superior to that of more sophisticated combinations. This empirical fact is referred to as the `forecast combination puzzle' in the literature. In this paper, we propose a combination method that exploits this puzzle. Rather than averaging over all forecasts, our method optimally selects forecasts for averaging. The problem of optimal selection is solved using integer programming, a solution approach that has witnessed astonishing advancements. We apply this new method to forecasts of real GDP growth and unemployment from the European Central Bank Survey of Professional Forecasters. The results show that it is optimal to select only a small number of the available forecasts and that averaging over these small subsets almost always provides performance that is superior to averaging over all forecasts. Importantly, this new method is consistently one of the best performers when evaluated against a wide range of alternative forecast combination methods.},
	Author = {Matsypura, Dmytro and Thompson, Ryan and Vasnev, Andrey L.},
	Date-Added = {2018-07-25 01:48:43 +0000},
	Date-Modified = {2018-07-25 01:48:54 +0000},
	Doi = {10.1016/j.omega.2017.11.0},
	Journal = {Omega},
	Keywords = {Forecast combination; Forecast combination puzzle; Macroeconomic forecasting; Integer programming; E},
	Number = {C},
	Pages = {165-175},
	Title = {{Optimal selection of expert forecasts with integer programming}},
	Url = {https://ideas.repec.org/a/eee/jomega/v78y2018icp165-175.html},
	Volume = {78},
	Year = 2018,
	Bdsk-Url-1 = {https://ideas.repec.org/a/eee/jomega/v78y2018icp165-175.html},
	Bdsk-Url-2 = {http://dx.doi.org/10.1016/j.omega.2017.11.0}}

@article{Claeskens:2016,
	Abstract = {This paper offers a theoretical explanation for the stylized fact that forecast combinations with estimated optimal weights often perform poorly in applications. The properties of the forecast combination are typically derived under the assumption that the weights are fixed, while in practice they need to be estimated. If the fact that the weights are random rather than fixed is taken into account during the optimality derivation, then the forecast combination will be biased (even when the original forecasts are unbiased), and its variance will be larger than in the fixed-weight case. In particular, there is no guarantee that the `optimal' forecast combination will be better than the equal-weight case, or even improve on the original forecasts. We provide the underlying theory, some special cases, and a numerical illustration.},
	Author = {Gerda Claeskens and Jan R. Magnus and Andrey L. Vasnev and Wendun Wang},
	Date-Added = {2018-02-05 01:33:58 +0000},
	Date-Modified = {2018-02-05 01:33:58 +0000},
	Doi = {https://doi.org/10.1016/j.ijforecast.2015.12.005},
	Issn = {0169-2070},
	Journal = {International Journal of Forecasting},
	Keywords = {Forecast combination, Optimal weights},
	Number = {3},
	Pages = {754 - 762},
	Title = {The forecast combination puzzle: A simple theoretical explanation},
	Url = {http://www.sciencedirect.com/science/article/pii/S0169207016000327},
	Volume = {32},
	Year = {2016},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0169207016000327},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.ijforecast.2015.12.005}}

@article{ChanPauwels:2018,
	Abstract = {This paper proposes a framework for the analysis of the theoretical properties of forecast combination, with the forecast performance being measured in terms of mean squared forecast errors (MSFE). Such a framework is useful for deriving all existing results with ease. In addition, it also provides insights into two forecast combination puzzles. Specifically, it investigates why a simple average of forecasts often outperforms forecasts from single models in terms of MSFEs, and why a more complicated weighting scheme does not always perform better than a simple average. In addition, this paper presents two new findings that are particularly relevant in practice. First, the MSFE of a forecast combination decreases as the number of models increases. Second, the conventional approach to the selection of optimal models, based on a simple comparison of MSFEs without further statistical testing, leads to a biased selection.},
	Author = {Chan, Felix and Pauwels, Laurent L.},
	Da = {2018/01/01/},
	Date-Added = {2018-02-05 01:33:54 +0000},
	Date-Modified = {2018-02-05 01:33:54 +0000},
	Doi = {https://doi.org/10.1016/j.ijforecast.2017.08.005},
	Isbn = {0169-2070},
	Journal = {International Journal of Forecasting},
	Keywords = {Forecast combination; Averaging; Optimal weights; Mean squared error},
	Number = {1},
	Pages = {64--74},
	Title = {Some theoretical results on forecast combinations},
	Ty = {JOUR},
	Url = {http://www.sciencedirect.com/science/article/pii/S0169207017300912},
	Volume = {34},
	Year = {2018},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0169207017300912},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.ijforecast.2017.08.005}}

@article{ChanPauwels:2017,
	Abstract = {Abstract This paper proposes a framework for the analysis of the theoretical properties of forecast combination, with the forecast performance being measured in terms of mean squared forecast errors (MSFE). Such a framework is useful for deriving all existing results with ease. In addition, it also provides insights into two forecast combination puzzles. Specifically, it investigates why a simple average of forecasts often outperforms forecasts from single models in terms of MSFEs, and why a more complicated weighting scheme does not always perform better than a simple average. In addition, this paper presents two new findings that are particularly relevant in practice. First, the MSFE of a forecast combination decreases as the number of models increases. Second, the conventional approach to the selection of optimal models, based on a simple comparison of MSFEs without further statistical testing, leads to a biased selection.},
	Author = {Felix Chan and Laurent L. Pauwels},
	Date-Added = {2017-12-12 02:40:26 +0000},
	Date-Modified = {2017-12-12 02:40:50 +0000},
	Doi = {https://doi.org/10.1016/j.ijforecast.2017.08.005},
	Issn = {0169-2070},
	Journal = {International Journal of Forecasting},
	Keywords = {Forecast combination, Averaging, Optimal weights, Mean squared error},
	Number = {1},
	Pages = {64 - 74},
	Title = {Some theoretical results on forecast combinations},
	Url = {http://www.sciencedirect.com/science/article/pii/S0169207017300912},
	Volume = {34},
	Year = {2018},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0169207017300912},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.ijforecast.2017.08.005}}

@article{Jose:2017,
	Abstract = { Properties of two large families of scale-free forecast accuracy measures that include popular measures such as mean absolute percentage error, relative error, and squared percentage error, are examined in this paper. We describe the optimal reports when forecasts are evaluated using these measures. We also provide analytic expressions for the optimal Bayes‚{\"A}{\^o} act associated with these measures under a general power transformation for several well-known probability distributions. We then show that using measures from these two families may inadvertently provide incentives for either pessimism or optimism among forecasters, i.e., rewarding underforecasts or overforecasts relative to some reference measure of central tendency. As an illustration of these concepts, we examine the use of these measures for model selection in a forecast aggregation example using stock price forecasts derived from the Thomson Reuters Institutional Brokers‚{\"A}{\^o} Estimate System. This example illustrates how aggregation methods that always yield lower estimates relative to the mean or median generally exhibit better scores using percentage error-based measures, while those that yield higher estimates compared to the mean or median will effectively rank higher when relative error-based measures are used. },
	Author = {Victor Richmond R. Jose},
	Date-Added = {2017-12-12 02:37:18 +0000},
	Date-Modified = {2017-12-12 02:37:28 +0000},
	Doi = {10.1287/opre.2016.1550},
	Eprint = {https://doi.org/10.1287/opre.2016.1550},
	Journal = {Operations Research},
	Number = {1},
	Pages = {200-211},
	Title = {Percentage and Relative Error Measures in Forecast Evaluation},
	Url = {https://doi.org/10.1287/opre.2016.1550},
	Volume = {65},
	Year = {2017},
	Bdsk-Url-1 = {https://doi.org/10.1287/opre.2016.1550},
	Bdsk-Url-2 = {http://dx.doi.org/10.1287/opre.2016.1550}}

@article{Moon:2011,
	Author = {Yongma Moon and Tao Yao},
	Date-Added = {2017-05-02 06:19:01 +0000},
	Date-Modified = {2017-05-02 06:20:17 +0000},
	Journal = {Computers \& Operations Research},
	Pages = {1251-1258},
	Title = {A robust mean absolute deviation model for portfolio optimization},
	Volume = {38},
	Year = {2011}}

@article{Hiroshi:1991,
	Author = {Hiroshi Konno and Hiroaki Yamazaki},
	Date-Added = {2017-05-02 06:16:17 +0000},
	Date-Modified = {2020-06-30 16:57:25 +1000},
	Journal = {Management Science},
	Number = {5},
	Pages = {519-531},
	Title = {Mean-Absolute Deviation Portfolio Optimization Model and Its Applications to {Tokyo} Stock Market},
	Volume = {37},
	Year = {1991}}

@article{Zhao:2015,
	Author = {Yichuan Zhao and Xueping Meng and Hanfang Yang},
	Date-Added = {2017-05-02 04:43:58 +0000},
	Date-Modified = {2017-05-02 04:45:41 +0000},
	Journal = {Computational Statistics and Data Analysis},
	Pages = {92-101},
	Title = {Jackknife empirical likelihood inference for the mean absolute deviation},
	Volume = {91},
	Year = {2015}}

@article{Wang:2013,
	Author = {S. Wang and Q. Meng and Z Liu},
	Date-Added = {2017-05-02 04:39:46 +0000},
	Date-Modified = {2017-05-02 04:42:19 +0000},
	Journal = {Journal of the operational research society},
	Month = {April},
	Number = {4},
	Pages = {622-628},
	Title = {On the weighting of the mean-absolute-deviation cost minimization model},
	Volume = {64},
	Year = {2013}}

@article{Gastwirth:1974,
	Author = {Joseph L. Gastwirth},
	Date-Added = {2017-05-02 04:34:21 +0000},
	Date-Modified = {2017-05-02 04:42:58 +0000},
	Journal = {Econometrica},
	Number = {1},
	Pages = {191-196},
	Title = {Large sample theory of some measures of income inequality},
	Volume = {42},
	Year = {1974}}

@unpublished{Segers:2014,
	Author = {Segers, Johan},
	Date-Added = {2017-03-17 07:57:21 +0000},
	Date-Modified = {2017-03-17 07:58:14 +0000},
	Note = {ISBA Discussion Paper - 2014/26},
	Title = {On the asymptotic distribution of the mean absolute deviation about the mean},
	Year = {2014}}

@article{Bassett:1978,
	Author = {Gilbert {Bassett Jr.} and Roger Koenker},
	Date-Added = {2017-03-17 07:52:07 +0000},
	Date-Modified = {2017-03-17 08:14:19 +0000},
	Journal = {Journal of the American Statistical Association},
	Month = {September},
	Number = {363},
	Pages = {618-622},
	Title = {Asymptotic Theory of Least Absolute Error Regression},
	Volume = {73},
	Year = {1978}}

@incollection{StockWatson:1999,
	Address = {Oxford},
	Author = {Stock, J. H. and M. W. Watson},
	Booktitle = {Cointegration, Causality and Forecasting: Festschrift in Honour of Clive W. J. Granger},
	Date-Added = {2017-03-17 07:35:29 +0000},
	Date-Modified = {2017-03-17 07:40:39 +0000},
	Editor = {R. F. Engle and H. White (Eds.)},
	Pages = {1-44},
	Publisher = {Oxford University Press},
	Title = {A comparison of linear and nonlinear models for forecasting macroeconomic time series},
	Year = {1999}}

@article{Armstrong:1989,
	Author = {Armstrong, J.S.},
	Date-Added = {2017-03-16 01:58:05 +0000},
	Date-Modified = {2017-03-16 01:58:52 +0000},
	Journal = {International Journal of Forecasting},
	Pages = {585-588},
	Title = {Combining Forecasts: The End of the Beginning or the Beginning of the End},
	Volume = {5},
	Year = {1989}}

@article{StockWatson:2005,
	Author = {Stock, James H. and Watson, Mark W.},
	Date-Added = {2017-03-16 01:15:56 +0000},
	Date-Modified = {2017-03-16 01:19:24 +0000},
	Journal = {TBA},
	Pages = {xx-xx},
	Title = {An empirical comparison of methods for forecasting using many predictors},
	Volume = {X},
	Year = {2005}}

@article{GuptaWilton:1987,
	Author = {A. Gupta and P. C. Wilton},
	Date-Added = {2017-03-16 00:55:30 +0000},
	Date-Modified = {2017-03-16 00:56:35 +0000},
	Journal = {Management Science},
	Pages = {356-372},
	Title = {Combination of Forecasts: An Extension},
	Volume = {33},
	Year = {1987}}

@article{Capistran:2009,
	Author = {Capistr{{\'a}}n, C. and Timmerann, A.},
	Date-Added = {2017-03-14 01:20:04 +0000},
	Date-Modified = {2020-06-29 15:14:26 +1000},
	Journal = {Journal of Business and Economic Statistics},
	Pages = {428-440},
	Title = {Forecast Combination with Entry and Exit of Experts},
	Volume = {27},
	Year = {2009},
	Bdsk-File-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxAsLi4vLi4vLi4vLi4vRG93bmxvYWRzL2luZm9ybXNfb3ByZTY1XzIwMC5iaWJPEQGgAAAAAAGgAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADR5/dCSCsAAAAKfA0WaW5mb3Jtc19vcHJlNjVfMjAwLmJpYgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAkbyzNZVb5IAAAAAAAAAAAAEAAIAAAkgAAAAAAAAAAAAAAAAAAAACURvd25sb2FkcwAAEAAIAADR53iyAAAAEQAIAADWVPECAAAAAQAMAAp8DQAJyWAAAphcAAIAPk1hY2ludG9zaCBIRDpVc2VyczoAbGF1cmVudDoARG93bmxvYWRzOgBpbmZvcm1zX29wcmU2NV8yMDAuYmliAA4ALgAWAGkAbgBmAG8AcgBtAHMAXwBvAHAAcgBlADYANQBfADIAMAAwAC4AYgBpAGIADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgAuVXNlcnMvbGF1cmVudC9Eb3dubG9hZHMvaW5mb3Jtc19vcHJlNjVfMjAwLmJpYgATAAEvAAAVAAIADv//AAAACAANABoAJABTAAAAAAAAAgEAAAAAAAAABQAAAAAAAAAAAAAAAAAAAfc=}}

@article{Aiolfi:2006,
	Abstract = {This paper considers measures of persistence in the (relative) forecasting performance of linear and nonlinear time-series models applied to a large cross-section of economic variables in the \{G7\} countries. We find strong evidence of persistence among top and bottom forecasting models and relate this to the possibility of improving performance through forecast combinations. We propose a new four-stage conditional model combination method that first sorts models into clusters based on their past performance, then pools forecasts within each cluster, followed by estimation of the optimal forecast combination weights for these clusters and shrinkage towards equal weights. These methods are shown to work well empirically in out-of-sample forecasting experiments. },
	Author = {Marco Aiolfi and Allan Timmermann},
	Date-Added = {2015-07-28 07:30:19 +0000},
	Date-Modified = {2015-07-28 07:30:31 +0000},
	Doi = {http://dx.doi.org/10.1016/j.jeconom.2005.07.015},
	Issn = {0304-4076},
	Journal = {Journal of Econometrics},
	Keywords = {Persistence in forecasting performance},
	Number = {1--2},
	Pages = {31 - 53},
	Title = {Persistence in forecasting performance and conditional combination strategies},
	Url = {http://www.sciencedirect.com/science/article/pii/S0304407605001661},
	Volume = {135},
	Year = {2006},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0304407605001661},
	Bdsk-Url-2 = {http://dx.doi.org/10.1016/j.jeconom.2005.07.015}}

@article{Pesaran:2007,
	Abstract = {In situations where a regression model is subject to one or more breaks it is shown that it can be optimal to use pre-break data to estimate the parameters of the model used to compute out-of-sample forecasts. The issue of how best to exploit the trade-off that might exist between bias and forecast error variance is explored and illustrated for the multivariate regression model under the assumption of strictly exogenous regressors. In practice when this assumption cannot be maintained and both the time and size of the breaks are unknown, the optimal choice of the observation window will be subject to further uncertainties that make exploiting the bias--variance trade-off difficult. To that end we propose a new set of cross-validation methods for selection of a single estimation window and weighting or pooling methods for combination of forecasts based on estimation windows of different lengths. Monte Carlo simulations are used to show when these procedures work well compared with methods that ignore the presence of breaks. },
	Author = {M. Hashem Pesaran and Allan Timmermann},
	Date-Added = {2015-07-20 03:52:26 +0000},
	Date-Modified = {2015-07-20 03:52:41 +0000},
	Doi = {http://dx.doi.org/10.1016/j.jeconom.2006.03.010},
	Issn = {0304-4076},
	Journal = {Journal of Econometrics},
	Keywords = {Forecast combination},
	Number = {1},
	Pages = {134 - 161},
	Title = {Selection of estimation window in the presence of breaks},
	Url = {http://www.sciencedirect.com/science/article/pii/S0304407606000418},
	Volume = {137},
	Year = {2007},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0304407606000418},
	Bdsk-Url-2 = {http://dx.doi.org/10.1016/j.jeconom.2006.03.010}}

@article{Pesaran:2002,
	Abstract = {Despite mounting empirical evidence to the contrary, the literature on predictability of stock returns almost uniformly assumes a time-invariant relationship between state variables and returns. In this paper, we propose a two-stage approach for forecasting of financial return series that are subject to breaks. The first stage adopts a reversed ordered Cusum (ROC) procedure to determine in real time when the most recent break has occurred. In the second stage, post-break data is used to estimate the parameters of the forecasting model. We compare this approach to existing alternatives for dealing with parameter instability such as the Bai--Perron method and the time-varying parameter (TVP) model. An out-of-sample forecasting experiment demonstrates considerable gains in market timing precision from adopting the proposed two-stage forecasting method. },
	Author = {M.Hashem Pesaran and Allan Timmermann},
	Date-Added = {2015-07-20 03:50:43 +0000},
	Date-Modified = {2015-07-20 03:50:54 +0000},
	Doi = {http://dx.doi.org/10.1016/S0927-5398(02)00007-5},
	Issn = {0927-5398},
	Journal = {Journal of Empirical Finance},
	Keywords = {Structural breaks},
	Number = {5},
	Pages = {495 - 510},
	Title = {Market timing and return prediction under model instability},
	Url = {http://www.sciencedirect.com/science/article/pii/S0927539802000075},
	Volume = {9},
	Year = {2002},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0927539802000075},
	Bdsk-Url-2 = {http://dx.doi.org/10.1016/S0927-5398(02)00007-5}}

@article{Pesaran:2013,
	Abstract = {Abstract This paper considers the problem of forecasting under continuous and discrete structural breaks and proposes weighting observations to obtain optimal forecasts in the \{MSFE\} sense. We derive optimal weights for one step ahead forecasts. Under continuous breaks, our approach largely recovers exponential smoothing weights. Under discrete breaks, we provide analytical expressions for optimal weights in models with a single regressor, and asymptotically valid weights for models with more than one regressor. It is shown that in these cases the optimal weight is the same across observations within a given regime and differs only across regimes. In practice, where information on structural breaks is uncertain, a forecasting procedure based on robust optimal weights is proposed. The relative performance of our proposed approach is investigated using Monte Carlo experiments and an empirical application to forecasting real \{GDP\} using the yield curve across nine industrial economies. },
	Author = {M. Hashem Pesaran and Andreas Pick and Mikhail Pranovich},
	Date-Added = {2015-07-20 03:47:49 +0000},
	Date-Modified = {2015-07-20 03:47:56 +0000},
	Doi = {http://dx.doi.org/10.1016/j.jeconom.2013.04.002},
	Issn = {0304-4076},
	Journal = {Journal of Econometrics},
	Keywords = {Exponential smoothing},
	Note = {Dynamic Econometric Modeling and Forecasting},
	Number = {2},
	Pages = {134 - 152},
	Title = {Optimal forecasts in the presence of structural breaks},
	Url = {http://www.sciencedirect.com/science/article/pii/S0304407613000687},
	Volume = {177},
	Year = {2013},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0304407613000687},
	Bdsk-Url-2 = {http://dx.doi.org/10.1016/j.jeconom.2013.04.002}}

@article{Tian:2014,
	Abstract = {Abstract This paper proposes two new weighting schemes that average forecasts based on different estimation windows in order to account for possible structural change. The first scheme weights the forecasts according to the values of reversed ordered \{CUSUM\} (ROC) test statistics, while the second weighting method simply assigns heavier weights to forecasts that use more recent information. Simulation results show that, when structural breaks are present, forecasts based on the first weighting scheme outperform those based on a procedure that simply uses \{ROC\} tests to choose and forecast from a single post-break estimation window. Combination forecasts based on our second weighting scheme outperform equally weighted combination forecasts. An empirical application based on a \{NAIRU\} Phillips curve model for the \{G7\} countries illustrates these findings, and also shows that combination forecasts can outperform the random walk forecasting model. },
	Author = {Jing Tian and Heather M. Anderson},
	Date-Added = {2015-07-16 03:48:56 +0000},
	Date-Modified = {2015-07-16 03:49:11 +0000},
	Doi = {http://dx.doi.org/10.1016/j.ijforecast.2013.06.003},
	Issn = {0169-2070},
	Journal = {International Journal of Forecasting},
	Keywords = {Weighted forecasts},
	Number = {1},
	Pages = {161 - 175},
	Title = {Forecast combinations under structural break uncertainty},
	Url = {http://www.sciencedirect.com/science/article/pii/S0169207013000897},
	Volume = {30},
	Year = {2014},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0169207013000897},
	Bdsk-Url-2 = {http://dx.doi.org/10.1016/j.ijforecast.2013.06.003}}

@article{Poncela:2011,
	Abstract = {This paper considers several methods of producing a single forecast from several individual ones. We compare ``standard'' but hard to beat combination schemes (such as the average of forecasts at each period, or consensus forecast and OLS-based combination schemes) with more sophisticated alternatives that involve dimension reduction techniques. Specifically, we consider principal components, dynamic factor models, partial least squares and sliced inverse regression. Our source of forecasts is the Survey of Professional Forecasters, which provides forecasts for the main \{US\} macroeconomic aggregates. The forecasting results show that partial least squares, principal component regression and factor analysis have similar performances (better than the usual benchmark models), but sliced inverse regression shows an extreme behavior (performs either very well or very poorly). },
	Author = {Pilar Poncela and Julio Rodr{\'\i}guez and Roc{\'\i}o S{\'a}nchez-Mangas and Eva Senra},
	Date-Added = {2015-07-16 03:46:35 +0000},
	Date-Modified = {2015-07-16 03:46:54 +0000},
	Doi = {http://dx.doi.org/10.1016/j.ijforecast.2010.01.012},
	Issn = {0169-2070},
	Journal = {International Journal of Forecasting},
	Keywords = {Survey of Professional Forecasters},
	Number = {2},
	Pages = {224 - 237},
	Title = {Forecast combination through dimension reduction techniques},
	Url = {http://www.sciencedirect.com/science/article/pii/S0169207010000221},
	Volume = {27},
	Year = {2011},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0169207010000221},
	Bdsk-Url-2 = {http://dx.doi.org/10.1016/j.ijforecast.2010.01.012}}

@article{ClemenWinkler:1986,
	Author = {Clemen, R. and R. Winkler},
	Date-Added = {2015-03-30 06:49:54 +0000},
	Date-Modified = {2015-03-30 07:05:31 +0000},
	Journal = {Journal of Business and Economic Statistics},
	Pages = {39-46},
	Title = {Combining Economic Forecasts},
	Volume = {4},
	Year = {1986},
	Bdsk-File-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxAkLi4vLi4vLi4vLi4vRG93bmxvYWRzL3NjaWVuY2UoNCkuYmliTxEBgAAAAAABgAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAyh5G9EgrAAAADxlwDnNjaWVuY2UoNCkuYmliAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAE5UvzR0pC8AAAAAAAAAAAABAACAAAJIAAAAAAAAAAAAAAAAAAAAAlEb3dubG9hZHMAABAACAAAyh3WdAAAABEACAAA0dIgPAAAAAEADAAPGXAADrTyAACY/wACADZNYWNpbnRvc2ggSEQ6VXNlcnM6AGxhdXJlbnQ6AERvd25sb2FkczoAc2NpZW5jZSg0KS5iaWIADgAeAA4AcwBjAGkAZQBuAGMAZQAoADQAKQAuAGIAaQBiAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAJlVzZXJzL2xhdXJlbnQvRG93bmxvYWRzL3NjaWVuY2UoNCkuYmliABMAAS8AABUAAgAO//8AAAAIAA0AGgAkAEsAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAABzw==}}

@article{ClementsHendry:2004,
	Author = {Hendry, D. and M. Clements},
	Date-Added = {2015-03-30 06:49:32 +0000},
	Date-Modified = {2015-03-30 07:04:48 +0000},
	Journal = {Econometrics Journal},
	Pages = {1-31},
	Title = {Pooling of Forecasts},
	Volume = {1},
	Year = {2004}}

@article{ClarkWest:2006,
	Abstract = {We consider using out-of-sample mean squared prediction errors (MSPEs) to evaluate the null that a given series follows a zero mean martingale difference against the alternative that it is linearly predictable. Under the null of no predictability, the population MSPE of the null "no change" model equals that of the linear alternative. We show analytically and via simulations that despite this equality, the alternative model's sample MSPE is expected to be greater than the null's. For rolling regression estimators of the alternative model's parameters, we propose and evaluate an asymptotically normal test that properly accounts for the upward shift of the sample MSPE of the alternative model. Our simulations indicate that our proposed procedure works well. {\copyright} 2005 Elsevier B.V. All rights reserved.},
	Affiliation = {Economic Research Department, Federal Reserve Bank of Kansas City, 925 Grand Blvd., Kansas City, MO 64198, United States; Department of Economics, University of Wisconsin, 1180 Observatory Drive, Madison, WI 53706-1393, United States},
	Author = {Clark, T.E.a and West, K.D.b},
	Author_Keywords = {Causality; Efficient markets; Exchange rate; Forecasting; Random walk; Testing},
	Date-Added = {2014-10-30 03:20:18 +0000},
	Date-Modified = {2014-10-30 03:20:29 +0000},
	Document_Type = {Article},
	Journal = {Journal of Econometrics},
	Note = {cited By (since 1996)81},
	Number = {1-2},
	Pages = {155-186},
	Source = {Scopus},
	Title = {Using out-of-sample mean squared prediction errors to test the martingale difference hypothesis},
	Url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-33748618701&partnerID=40&md5=255a7ef1adabe8fd27b360ed24359570},
	Volume = {135},
	Year = {2006},
	Bdsk-File-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxAqLi4vLi4vLi4vLi4vLlRyYXNoL3BlcmljbGVzXzE0NjgwMDg0NzQuYmliTxEBZgAAAAABZgACAAANTWFjaW50b3NoIFNTRAAAAAAAAAAAAAAAAAAAAAAAAEJEAAH/////F3BlcmljbGVzXzE0NjgwMDg0NzQuYmliAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAP////8AAAAAAAAAAAAAAAAABAACAAAKIGN1AAAAAAAAAAAAAAAAAAYuVHJhc2gAAgAuLzpVc2VyczpsYXVyZW50Oi5UcmFzaDpwZXJpY2xlc18xNDY4MDA4NDc0LmJpYgAOADAAFwBwAGUAcgBpAGMAbABlAHMAXwAxADQANgA4ADAAMAA4ADQANwA0AC4AYgBpAGIADwAcAA0ATQBhAGMAaQBuAHQAbwBzAGgAIABTAFMARAASACxVc2Vycy9sYXVyZW50Ly5UcmFzaC9wZXJpY2xlc18xNDY4MDA4NDc0LmJpYgATAAEvAAAVAAIADv//AAAACAANABoAJABRAAAAAAAAAgEAAAAAAAAABQAAAAAAAAAAAAAAAAAAAbs=},
	Bdsk-Url-1 = {http://www.scopus.com/inward/record.url?eid=2-s2.0-33748618701&partnerID=40&md5=255a7ef1adabe8fd27b360ed24359570}}

@unpublished{Elliott:2011,
	Author = {Graham Elliott},
	Date-Added = {2014-10-16 01:52:06 +0000},
	Date-Modified = {2017-03-14 01:24:03 +0000},
	Month = {September},
	Note = {University of California, San Diego},
	Title = {Averaging and the Optimal Combination of Forecasts},
	Url = {http://econweb.ucsd.edu/~grelliott/AveragingOptimal.pdf},
	Year = {2011},
	Bdsk-Url-1 = {http://econweb.ucsd.edu/~grelliott/AveragingOptimal.pdf}}

@article{ClarkWest:2007,
	Abstract = {Forecast evaluation often compares a parsimonious null model to a larger model that nests the null model. Under the null that the parsimonious model generates the data, the larger model introduces noise into its forecasts by estimating parameters whose population values are zero. We observe that the mean squared prediction error (MSPE) from the parsimonious model is therefore expected to be smaller than that of the larger model. We describe how to adjust \{MSPEs\} to account for this noise. We propose applying standard methods [West, K.D., 1996. Asymptotic inference about predictive ability. Econometrica 64, 1067--1084] to test whether the adjusted mean squared error difference is zero. We refer to nonstandard limiting distributions derived in Clark and McCracken [2001. Tests of equal forecast accuracy and encompassing for nested models. Journal of Econometrics 105, 85--110; 2005a. Evaluating direct multistep forecasts. Econometric Reviews 24, 369--404] to argue that use of standard normal critical values will yield actual sizes close to, but a little less than, nominal size. Simulation evidence supports our recommended procedure. },
	Author = {Todd E. Clark and Kenneth D. West},
	Date-Added = {2014-08-17 06:08:18 +0000},
	Date-Modified = {2014-08-17 06:08:29 +0000},
	Doi = {http://dx.doi.org/10.1016/j.jeconom.2006.05.023},
	Issn = {0304-4076},
	Journal = {Journal of Econometrics},
	Keywords = {Principle of parsimony},
	Note = {50th Anniversary Econometric Institute},
	Number = {1},
	Pages = {291 - 311},
	Title = {Approximately normal tests for equal predictive accuracy in nested models},
	Url = {http://www.sciencedirect.com/science/article/pii/S0304407606000960},
	Volume = {138},
	Year = {2007},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0304407606000960},
	Bdsk-Url-2 = {http://dx.doi.org/10.1016/j.jeconom.2006.05.023}}

@article{Vasnev:2014,
	Author = {Claeskens, Gerda and Jan R. Magnus and Andrey L. Vasnev and Wendun Wang},
	Date-Added = {2014-08-17 05:01:12 +0000},
	Date-Modified = {2017-03-15 22:44:17 +0000},
	Journal = {International Journal of Forecasting},
	Number = {3},
	Pages = {754-62},
	Title = {A Simple Theoretical Explanation of the Forecast Combination Puzzle},
	Volume = {32},
	Year = {2016}}

@article{SmithWallis:2009,
	Abstract = {This article presents a formal explanation of the forecast combination puzzle, that simple combinations of point forecasts are repeatedly found to outperform sophisticated weighted combinations in empirical applications. The explanation lies in the effect of finite-sample error in estimating the combining weights. A small Monte Carlo study and a reappraisal of an empirical study by Stock and Watson [Federal Reserve Bank of Richmond Economic Quarterly (2003) Vol. 89/3, pp. 71--90] support this explanation. The Monte Carlo evidence, together with a large-sample approximation to the variance of the combining weight, also supports the popular recommendation to ignore forecast error covariances in estimating the weight.},
	Author = {Smith, Jeremy and Wallis, Kenneth F.},
	Date-Added = {2014-08-17 05:00:04 +0000},
	Date-Modified = {2014-08-17 05:40:37 +0000},
	Doi = {10.1111/j.1468-0084.2008.00541.x},
	Issn = {1468-0084},
	Journal = {Oxford Bulletin of Economics and Statistics},
	Keywords = {C22, C53, E37},
	Number = {3},
	Pages = {331--355},
	Publisher = {Blackwell Publishing Ltd},
	Title = {A Simple Explanation of the Forecast Combination Puzzle},
	Url = {http://dx.doi.org/10.1111/j.1468-0084.2008.00541.x},
	Volume = {71},
	Year = {2009},
	Bdsk-Url-1 = {http://dx.doi.org/10.1111/j.1468-0084.2008.00541.x}}

@article{StockWatson:2003,
	Author = {Stock, James H. and Watson, Mark W.},
	Date-Added = {2014-08-17 04:53:01 +0000},
	Date-Modified = {2014-08-17 04:54:21 +0000},
	Journal = {FRB Richmond Economic Quarterly},
	Number = {3},
	Pages = {71-90},
	Title = {How Did Leading Indicator Forecasts Perform during the 2001 Recession?},
	Volume = {89},
	Year = {2003}}

@article{StockWatson:2004,
	Abstract = {This paper uses forecast combination methods to forecast output growth in a seven-country quarterly economic data set covering 1959--1999, with up to 73 predictors per country. Although the forecasts based on individual predictors are unstable over time and across countries, and on average perform worse than an autoregressive benchmark, the combination forecasts often improve upon autoregressive forecasts. Despite the unstable performance of the constituent forecasts, the most successful combination forecasts, like the mean, are the least sensitive to the recent performance of the individual forecasts. While consistent with other evidence on the success of simple combination forecasts, this finding is difficult to explain using the theory of combination forecasting in a stationary environment. Copyright {\copyright} 2004 John Wiley & Sons, Ltd.},
	Author = {Stock, James H. and Watson, Mark W.},
	Date-Added = {2014-08-17 04:46:45 +0000},
	Date-Modified = {2014-08-17 04:47:05 +0000},
	Doi = {10.1002/for.928},
	Issn = {1099-131X},
	Journal = {Journal of Forecasting},
	Keywords = {macroeconomic forecasting, high-dimensional forecasting, time-varying parameters, forecast pooling},
	Number = {6},
	Pages = {405--430},
	Publisher = {John Wiley & Sons, Ltd.},
	Title = {Combination forecasts of output growth in a seven-country data set},
	Url = {http://dx.doi.org/10.1002/for.928},
	Volume = {23},
	Year = {2004},
	Bdsk-Url-1 = {http://dx.doi.org/10.1002/for.928}}

@article{Clemen:1989,
	Author = {Clemen, R. T.},
	Date-Added = {2014-08-17 04:39:13 +0000},
	Date-Modified = {2014-08-17 04:39:13 +0000},
	Journal = {International Journal of Forecasting},
	Pages = {559-583},
	Title = {Combining forecasts: a review and annotated bibliography},
	Volume = {5},
	Year = {1989}}

@article{BatesGranger:1969,
	Author = {Bates, J. M. and Granger, C. W. J.},
	Date-Added = {2014-08-17 04:39:05 +0000},
	Date-Modified = {2017-12-09 03:30:35 +0000},
	Journal = {Operations Research Quarterly},
	Pages = {451-468},
	Title = {The combination of forecasts},
	Volume = {20},
	Year = {1969}}

@article{hsiao_wan:2014,
	Author = {Cheng Hsiao and Shui Ki Wan},
	Journal = {Journal of Econometrics},
	Pages = {294-309},
	Title = {Is there an optimal forecast combination},
	Volume = 178,
	Year = 2014}

@article{granger_ramanathan:1984,
	Author = {C.W.J. Granger and R. Ramanathan},
	Journal = {Journal of Forecasting},
	Pages = {197-204},
	Title = {Improved methods of combining forecast accuracy},
	Volume = 19,
	Year = 1984,
	Bdsk-File-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxAqLi4vLi4vLi4vLi4vRG93bmxvYWRzLzAwNDE1NTUzNjc5MDA0MDcuYmliTxEBYgAAAAABYgACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAAAAAAEJEAAH/////FDAwNDE1NTUzNjc5MDA0MDcuYmliAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAP////8AAAAAAAAAAAAAAAAABAACAAAKIGN1AAAAAAAAAAAAAAAAAAlEb3dubG9hZHMAAAIALi86VXNlcnM6bGF1cmVudDpEb3dubG9hZHM6MDA0MTU1NTM2NzkwMDQwNy5iaWIADgAqABQAMAAwADQAMQA1ADUANQAzADYANwA5ADAAMAA0ADAANwAuAGIAaQBiAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIALFVzZXJzL2xhdXJlbnQvRG93bmxvYWRzLzAwNDE1NTUzNjc5MDA0MDcuYmliABMAAS8AABUAAgAO//8AAAAIAA0AGgAkAFEAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAABtw==}}

@incollection{timmermann:2006,
	Author = {A. Timmermann},
	Booktitle = {Handbook of Economic Forecasting, Vol 1.},
	Editor = {G. Elliott and C.W.J. Granger and A. Timmermann},
	Publisher = {Elsevier, Amsterdam},
	Title = {Forecast Combinations},
	Year = 2006}

@article{diebold_mariano:1995,
	Author = {F.X. Diebold and R. Mariano},
	Journal = {Journal of Business and Economic Statistics},
	Pages = {253-265},
	Title = {Comparing Predictive Accuracy},
	Volume = 13,
	Year = 1995}

@article{harvey_leybourne_newbold:1997,
	Author = {D. Harvey and S. Leybourne and P. Newbold},
	Journal = {International Journal of Forecasting},
	Pages = {281-291},
	Title = {Testing the equality of prediction mean square errors},
	Volume = 13,
	Year = 1997}

@article{clark_mccracken:2001,
	Author = {T.E. Clark and M.W. McCracken},
	Journal = {Journal of Econometrics},
	Pages = {85-110},
	Title = {Tests of equal forecast accuracy and encompassing for nested models},
	Volume = 105,
	Year = 2001}

@article{clark_west:2007,
	Author = {T.E. Clark and K.D. West},
	Journal = {Journal of Econometrics},
	Pages = {291-311},
	Title = {Approximately normal tests for equal predictive accuracy in nested models},
	Volume = 138,
	Year = 2007}

@article{azzalini:1985,
	Author = {A. Azzalini},
	Journal = {Scandinavian Journal of Statistics},
	Pages = {171-178},
	Title = {A class of distributions which includes the normal ones},
	Year = 1985}

@book{white:1999,
	Author = {Halbert White},
	Publisher = {Academic Press},
	Title = {Asymptotic theory for econometricians},
	Year = 1999}

@article{Cook:1951,
	Author = {Cook, M B},
	File = {:Users/229922i/research/papers/Cook/Biometrika/Cook - 1951 - Bi-Variate k-Statistics and Cumulants of Their Joint Sampling Distribution.pdf:pdf},
	Journal = {Biometrika},
	Number = {1},
	Pages = {179--195},
	Title = {{Bi-Variate k-Statistics and Cumulants of Their Joint Sampling Distribution}},
	Volume = {38},
	Year = {1951}}

@article{Iwashita:1994,
	Author = {Iwashita, Toshiya and Siotani, Minoru},
	Doi = {10.2307/3315589},
	File = {:Users/229922i/research/papers/Iwashita, Siotani/Canadian Journal of Statistics/Iwashita, Siotani - 1994 - Asymptotic distributions of functions of a sample covariance matrix under the elliptical distribution.pdf:pdf},
	Issn = {03195724},
	Journal = {Canadian Journal of Statistics},
	Keywords = {ams 1985 subject cluss,arid phrases,asymptotic distribution,asymptotic expansion,bution,cations,differential operator method,elliptical distri-,functions of sample covariance,kurtosis parameter,matrix,model,primary 62h 10,secondary 62e20,zonal polynomials},
	Number = {2},
	Pages = {273--283},
	Title = {{Asymptotic distributions of functions of a sample covariance matrix under the elliptical distribution}},
	Url = {http://onlinelibrary.wiley.com/doi/10.2307/3315589/full{\%}5Cnhttp://doi.wiley.com/10.2307/3315589},
	Volume = {22},
	Year = {1994},
	Bdsk-Url-1 = {http://dx.doi.org/10.2307/3315589}}

@article{Kato:2009,
	Author = {Kato, Kengo},
	Doi = {10.1016/j.jmva.2009.02.008},
	File = {:Users/229922i/research/papers/Kato/Journal of Multivariate Analysis/Kato - 2009 - Asymptotics for argmin processes Convexity arguments.pdf:pdf},
	Issn = {0047259X},
	Journal = {Journal of Multivariate Analysis},
	Keywords = {Argmin process,Convexity argument,Parametrized objective function,Regression quantile process,Representation theorem,Threshold regression},
	Number = {8},
	Pages = {1816--1829},
	Publisher = {Elsevier Inc.},
	Title = {{Asymptotics for argmin processes: Convexity arguments}},
	Url = {http://dx.doi.org/10.1016/j.jmva.2009.02.008},
	Volume = {100},
	Year = {2009},
	Bdsk-Url-1 = {http://dx.doi.org/10.1016/j.jmva.2009.02.008}}

@article{Smith:1994,
	Author = {Smith, Richard L.},
	File = {:Users/229922i/research/papers/Smith/Biometrika/Smith - 1994 - Nonregular Regression.pdf:pdf},
	Journal = {Biometrika},
	Number = {1},
	Pages = {173--183},
	Title = {{Nonregular Regression}},
	Volume = {81},
	Year = {1994}}

@article{Knight:2001,
	Author = {Knight, Keith},
	File = {:Users/229922i/research/papers/Knight/Extremes/Knight - 2001 - Limiting distributions of linear programming estimators.pdf:pdf},
	Issn = {1386-1999},
	Journal = {Extremes},
	Keywords = {epi-convergence,extreme value distribution,linear programming estimator},
	Number = {2},
	Pages = {87--103},
	Title = {{Limiting distributions of linear programming estimators}},
	Url = {http://link.springer.com/article/10.1023/A{\%}3A1013991808181},
	Year = {2001}}

@article{Geyer:1994,
	Author = {Geyer, Charles J.},
	File = {:Users/229922i/research/papers/Geyer/The Annals of Statistics/Geyer - 1994 - On the Asymptotics of Constrained M-Estimation.pdf:pdf},
	Journal = {The Annals of Statistics},
	Number = {4},
	Pages = {1993--2010},
	Title = {{On the Asymptotics of Constrained M-Estimation}},
	Volume = {22},
	Year = {1994}}

@article{Knight:1998,
	Author = {Knight, Keith},
	File = {:Users/229922i/research/papers/Knight/The Annals of Statistics/Knight - 1998 - Limiting Distributions for L1 Regression Estimators under General Conditions.pdf:pdf},
	Journal = {The Annals of Statistics},
	Number = {2},
	Pages = {755--770},
	Title = {{Limiting Distributions for L1 Regression Estimators under General Conditions}},
	Volume = {26},
	Year = {1998}}

@article{Phillips:1991,
	Author = {Phillips, PCB},
	Doi = {10.1017/S0266466600004709},
	File = {:Users/229922i/research/papers/Phillips/Econometric Theory/Phillips - 1991 - A shortcut to LAD estimator asymptotics.pdf:pdf},
	Issn = {14694360 02664666},
	Journal = {Econometric Theory},
	Number = {4},
	Pages = {450--463},
	Title = {{A shortcut to LAD estimator asymptotics}},
	Url = {http://journals.cambridge.org/abstract{\_}S0266466600004709},
	Volume = {7},
	Year = {1991},
	Bdsk-Url-1 = {http://journals.cambridge.org/abstract%7B%5C_%7DS0266466600004709},
	Bdsk-Url-2 = {http://dx.doi.org/10.1017/S0266466600004709}}

@book{rudin:1976,
	Author = {Walter Rudin},
	Publisher = {McGraw-Hill},
	Title = {Principles of Mathematical Analysis. Third Edition},
	Year = 1976}
